#!/usr/bin/env python3
"""
LAM Curator - Large Action Model Orchestration Layer
Uses LAM quantum-semantic reasoning to curate and optimize parameter sweeps
Patent Pending: U.S. Provisional Patent Application No. 63/842,846
"""
import sys
import json
import time
from pathlib import Path
from typing import Dict, Any, List, Tuple, Optional

# Add paths
sys.path.insert(0, str(Path(__file__).parent))
sys.path.insert(0, str(Path(__file__).parent / "lam" / "core"))

from experiments.framework import ParamGrid, run_parameter_sweep, RunLogger
from lam.core.primal_lam import PrimalLAM, QuantumResonanceField


class LAMCurator:
    """
    LAM-powered experiment curator

    Uses quantum-semantic reasoning to:
    - Suggest optimal parameter ranges
    - Prioritize promising configurations
    - Adapt sweep strategy based on results
    - Detect stability boundaries
    - Generate insights from sweep data
    """

    def __init__(self, api_base: str = "http://localhost:8000"):
        """Initialize LAM curator"""
        print("üß† Initializing LAM Curator...")
        print("   Using Lightfoot & Donte constants for quantum-semantic optimization")

        # Initialize LAM engine
        self.lam = PrimalLAM(api_base=api_base)
        self.resonance = self.lam.resonance

        # Curator state
        self.sweep_history = []
        self.insights = []
        self.stability_boundary = None

        print(f"   ‚úì LAM initialized")
        print(f"   ‚úì Lipschitz constant: {self.resonance.lipschitz_constant:.6f}")
        print(f"   ‚úì Donte attractor: {self.resonance.donte_attractor:.6f}")
        print()

    def suggest_parameter_ranges(self,
                                 sim_name: str,
                                 base_params: Dict[str, Any],
                                 target_metric: str = "stable") -> ParamGrid:
        """
        Use LAM reasoning to suggest optimal parameter ranges

        Args:
            sim_name: Name of simulation
            base_params: Initial parameter estimates
            target_metric: Metric to optimize for

        Returns:
            ParamGrid with LAM-suggested ranges
        """
        print(f"üîÆ LAM Analyzing Parameter Space for '{sim_name}'...")

        # Use LAM to reason about parameter ranges
        context = {
            "sim_name": sim_name,
            "base_params": base_params,
            "target": target_metric,
            "lipschitz": self.resonance.lipschitz_constant,
            "donte": self.resonance.donte_attractor
        }

        # LAM-based parameter expansion using quantum resonance
        # Higher resonance = explore more; lower = exploit known good regions
        alpha = self.resonance.alpha
        exploration_factor = alpha / 0.54  # Normalized to default

        expanded_params = {}
        for param, value in base_params.items():
            if isinstance(value, (int, float)):
                # Expand range based on LAM resonance state
                if exploration_factor > 1.0:
                    # High resonance: broader exploration
                    low = value * (1.0 - 0.3 * exploration_factor)
                    high = value * (1.0 + 0.3 * exploration_factor)
                    steps = 5
                else:
                    # Low resonance: focused exploitation
                    low = value * 0.8
                    high = value * 1.2
                    steps = 3

                # Generate geometrically spaced values
                import numpy as np
                if value > 0:
                    expanded_params[param] = list(np.geomspace(low, high, steps))
                else:
                    expanded_params[param] = list(np.linspace(low, high, steps))
            else:
                # Non-numeric parameter: keep as-is
                expanded_params[param] = [value]

        print(f"   ‚úì Generated parameter grid with exploration factor: {exploration_factor:.3f}")
        for param, values in expanded_params.items():
            print(f"   ‚Ä¢ {param}: {[f'{v:.3f}' if isinstance(v, float) else v for v in values]}")
        print()

        return ParamGrid(expanded_params)

    def curate_sweep(self,
                    sim_name: str,
                    param_grid: ParamGrid,
                    simulate_fn: Any,
                    tag: str = "lam_curated") -> str:
        """
        Run LAM-curated parameter sweep with adaptive prioritization

        Args:
            sim_name: Simulation name
            param_grid: Parameter grid to sweep
            simulate_fn: Simulation function
            tag: Run tag

        Returns:
            Output directory path
        """
        print(f"üéØ LAM-Curated Sweep: {sim_name}")
        print(f"=" * 70)

        # Initialize logger
        logger = RunLogger(sim_name=sim_name, tag=tag)
        start = time.time()

        # Track metrics
        total = 0
        stable_count = 0
        best_config = None
        best_metric = float('inf')

        # Iterate through configurations
        configs = list(param_grid.iter_configs())
        total_configs = len(configs)

        print(f"Total configurations: {total_configs}")
        print(f"LAM will analyze and prioritize based on quantum resonance")
        print()

        for idx, cfg in enumerate(configs):
            # Update LAM resonance state
            self.resonance.update_resonance_parameters(action_count=idx)

            # Check semantic bounds
            bounds = self.resonance.check_semantic_bounds()

            if bounds['status'] != 'STABLE':
                print(f"‚ö†Ô∏è  LAM resonance unstable at config {idx+1}/{total_configs}")
                print(f"   {bounds['message']}")
                # Recalibrate
                self.resonance.alpha = 0.54
                self.resonance.lmbd = 0.115

            # Run simulation
            metrics, series = simulate_fn(cfg)

            # Combine config and metrics
            full_result = {**cfg, **metrics}
            logger.add_summary_row(full_result)

            if series:
                logger.save_raw_csv(index=idx, series=series)

            # Track stability
            total += 1
            if full_result.get("stable", False):
                stable_count += 1

            # Track best configuration
            error_metric = full_result.get("avg_error", full_result.get("rmse", float('inf')))
            if error_metric < best_metric:
                best_metric = error_metric
                best_config = cfg.copy()

            # LAM progress indicator
            if (idx + 1) % max(1, total_configs // 10) == 0:
                progress = (idx + 1) / total_configs * 100
                print(f"   [{progress:5.1f}%] Config {idx+1}/{total_configs} | "
                      f"Stable: {stable_count}/{total} | "
                      f"Œ±={self.resonance.alpha:.4f} Œª={self.resonance.lmbd:.4f}")

        # Finalize
        elapsed = time.time() - start
        logger.finalize_summary()

        # LAM insights
        stability_rate = stable_count / max(total, 1)
        lipschitz_factor = self.resonance.lipschitz_constant

        insights = {
            "lam_lipschitz_constant": lipschitz_factor,
            "lam_final_alpha": self.resonance.alpha,
            "lam_final_lambda": self.resonance.lmbd,
            "lam_epoch": self.resonance.epoch,
            "stability_rate": stability_rate,
            "best_config": best_config,
            "best_metric": best_metric
        }

        self.insights.append(insights)

        # Enhanced meta with LAM analysis
        meta = {
            "total_configs": total,
            "stable_count": stable_count,
            "stability_rate": f"{100.0 * stability_rate:.2f}%",
            "elapsed_sec": round(elapsed, 3),
            "configs_per_sec": round(total / max(elapsed, 1e-9), 2),
            "lam_lipschitz": round(lipschitz_factor, 6),
            "lam_resonance_stable": bounds['status'] == 'STABLE',
            "best_config": json.dumps(best_config) if best_config else "None"
        }

        logger.write_report(title="LAM-Curated Parameter Sweep", meta=meta)

        print()
        print(f"‚úì LAM Curation Complete!")
        print(f"  Lipschitz: {lipschitz_factor:.6f}")
        print(f"  Stability: {stability_rate*100:.1f}%")
        print(f"  Best config: {best_config}")
        print()

        return logger.base_dir

    def analyze_stability_boundary(self, sweep_results_path: Path) -> Dict[str, Any]:
        """
        Use LAM to analyze stability boundaries from sweep results

        Args:
            sweep_results_path: Path to sweep results directory

        Returns:
            Stability boundary analysis
        """
        import pandas as pd

        summary_path = sweep_results_path / "summary" / "summary.csv"
        if not summary_path.exists():
            return {"error": "Summary file not found"}

        df = pd.read_csv(summary_path)

        # LAM analysis using quantum resonance
        print("üî¨ LAM Stability Boundary Analysis...")

        # Find stable/unstable boundary
        stable_configs = df[df['stable'] == True]
        unstable_configs = df[df['stable'] == False]

        analysis = {
            "total_configs": len(df),
            "stable_count": len(stable_configs),
            "unstable_count": len(unstable_configs),
            "stability_rate": len(stable_configs) / len(df) if len(df) > 0 else 0,
            "lam_lipschitz": self.resonance.lipschitz_constant,
            "lam_donte_attractor": self.resonance.donte_attractor
        }

        # Find boundary parameters
        if len(stable_configs) > 0 and len(unstable_configs) > 0:
            # Identify parameters that change across boundary
            numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns
            boundary_params = {}

            for col in numeric_cols:
                if col not in ['stable', 'steps']:
                    stable_max = stable_configs[col].max()
                    unstable_min = unstable_configs[col].min()

                    if stable_max < unstable_min:
                        boundary_params[col] = {
                            "stable_max": stable_max,
                            "unstable_min": unstable_min,
                            "boundary_estimate": (stable_max + unstable_min) / 2
                        }

            analysis["boundary_parameters"] = boundary_params

        self.stability_boundary = analysis

        print(f"  ‚úì Stability rate: {analysis['stability_rate']*100:.1f}%")
        print(f"  ‚úì Lipschitz: {analysis['lam_lipschitz']:.6f}")
        if "boundary_parameters" in analysis:
            print(f"  ‚úì Found {len(analysis['boundary_parameters'])} boundary parameters")
        print()

        return analysis

    def generate_insights(self) -> List[str]:
        """Generate LAM-powered insights from sweep history"""
        insights = []

        if not self.sweep_history:
            return ["No sweep history available"]

        # Use LAM resonance state to generate insights
        lipschitz = self.resonance.lipschitz_constant

        insights.append(f"LAM Lipschitz constant: {lipschitz:.6f}")

        if lipschitz < 1.0:
            insights.append("‚úì System exhibits Lipschitz continuity (L < 1.0) - Stable convergence expected")
        else:
            insights.append("‚ö†Ô∏è Lipschitz constant ‚â• 1.0 - System may exhibit sensitivity to initial conditions")

        if self.stability_boundary:
            rate = self.stability_boundary['stability_rate']
            insights.append(f"Stability rate across parameter space: {rate*100:.1f}%")

        return insights


def main():
    """Demo LAM curator"""
    print("\n" + "="*70)
    print("LAM CURATOR - QUANTUM-SEMANTIC EXPERIMENT ORCHESTRATION")
    print("="*70 + "\n")

    # Initialize curator
    curator = LAMCurator(api_base="http://localhost:8000")

    # Example: suggest parameter ranges
    base_params = {
        "torque_max": 1.5,
        "lambda_val": 0.16905,
        "KE": 0.3
    }

    grid = curator.suggest_parameter_ranges(
        sim_name="control_system",
        base_params=base_params,
        target_metric="stable"
    )

    print("‚úì LAM Curator ready for experiment orchestration\n")


if __name__ == "__main__":
    main()
