{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/STLNFTART/MotorHandPro/blob/main/notebooks/experiments/04_benchmark_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark Analysis\n\nPerformance benchmarking and metrics analysis for Primal Logic implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import sys\nif 'google.colab' in sys.modules:\n    !pip install numpy matplotlib pandas\n    !git clone https://github.com/STLNFTART/MotorHandPro.git\n    sys.path.append('/content/MotorHandPro')\nelse:\n    sys.path.append('..' if 'notebooks' not in str(Path.cwd()) else '../..')\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and analyze benchmark data from experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from pathlib import Path\nimport time\n\n# Benchmark Primal Logic\nclass PrimalBenchmark:\n    def __init__(self):\n        self.lambda_val = 0.16905\n        self.Ec = 0.0\n        \n    def update(self, error, dt):\n        self.Ec = self.Ec * np.exp(-self.lambda_val * dt) + error * dt\n        psi = error + self.lambda_val * self.Ec\n        return psi\n\ndef benchmark_iterations(n_iter=100000):\n    controller = PrimalBenchmark()\n    errors = np.random.randn(n_iter)\n    dt = 0.001\n    \n    start = time.perf_counter()\n    for e in errors:\n        controller.update(e, dt)\n    end = time.perf_counter()\n    \n    return (end - start) * 1000, n_iter\n\ntotal_time, n = benchmark_iterations()\nprint(f'Benchmark Results:')\nprint(f'Total time: {total_time:.2f} ms')\nprint(f'Iterations: {n}')\nprint(f'Average: {total_time*1000/n:.2f} \u00b5s per iteration')"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "colab": {
   "provenance": [],
   "include_colab_link": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}