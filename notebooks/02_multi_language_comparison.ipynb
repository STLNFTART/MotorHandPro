{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/STLNFTART/MotorHandPro/blob/main/notebooks/02_multi_language_comparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Language Implementation Comparison\n",
    "\n",
    "MotorHandPro implements the Primal Logic framework in multiple programming languages:\n",
    "- **Python**: Prototyping and experimentation\n",
    "- **APL**: Array-based mathematical operations\n",
    "- **Prolog**: Logic-based reasoning and compliance checking\n",
    "- **D**: High-performance compiled implementations\n",
    "\n",
    "This notebook compares implementations across languages and provides guidance on when to use each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Setup for Google Colab\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    !pip install numpy matplotlib pandas\n",
    "    !git clone https://github.com/STLNFTART/MotorHandPro.git\n",
    "    sys.path.append('/content/MotorHandPro')\n",
    "else:\n",
    "    sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from time import perf_counter"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Python Implementation\n",
    "\n",
    "Python is ideal for:\n",
    "- Rapid prototyping\n",
    "- Data analysis and visualization\n",
    "- Integration with ML/AI libraries\n",
    "- Interactive experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Python Primal Logic implementation\n",
    "class PrimalLogicPython:\n",
    "    \"\"\"Pure Python implementation of Primal Logic\"\"\"\n",
    "    \n",
    "    def __init__(self, lambda_val=0.16905, donte=149.9992314000):\n",
    "        self.lambda_val = lambda_val\n",
    "        self.donte = donte\n",
    "        self.psi = 0.0\n",
    "        self.gamma = 0.0\n",
    "        self.Ec = 0.0\n",
    "        \n",
    "    def update(self, error, dt):\n",
    "        \"\"\"Update internal states\"\"\"\n",
    "        # Exponential memory decay\n",
    "        decay = np.exp(-self.lambda_val * dt)\n",
    "        self.Ec = self.Ec * decay + error * dt\n",
    "        \n",
    "        # Primal state updates\n",
    "        self.psi = error + self.lambda_val * self.Ec\n",
    "        self.gamma = self.donte * (1.0 - np.exp(-abs(self.psi) / self.donte))\n",
    "        \n",
    "        return self.psi, self.gamma, self.Ec\n",
    "\n",
    "# Benchmark Python implementation\n",
    "def benchmark_python(iterations=10000):\n",
    "    controller = PrimalLogicPython()\n",
    "    dt = 0.001\n",
    "    \n",
    "    start = perf_counter()\n",
    "    for i in range(iterations):\n",
    "        error = np.sin(i * 0.01)\n",
    "        controller.update(error, dt)\n",
    "    end = perf_counter()\n",
    "    \n",
    "    return (end - start) * 1000  # Convert to ms\n",
    "\n",
    "python_time = benchmark_python()\n",
    "print(f\"Python execution time: {python_time:.2f} ms for 10,000 iterations\")\n",
    "print(f\"Average per iteration: {python_time/10:.2f} µs\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. APL Implementation\n",
    "\n",
    "APL excels at:\n",
    "- Array operations\n",
    "- Mathematical transformations\n",
    "- Concise expression of algorithms\n",
    "- Signal processing\n",
    "\n",
    "### APL Code Example\n",
    "\n",
    "```apl\n",
    "⍝ Primal Logic Core in APL\n",
    "LAMBDA ← 0.16905\n",
    "DONTE ← 149.9992314000\n",
    "\n",
    "⍝ Exponential decay weights\n",
    "weights ← {⍵×*-LAMBDA×⍺}\n",
    "\n",
    "⍝ Primal state update\n",
    "update_psi ← {error + LAMBDA × Ec}\n",
    "\n",
    "⍝ Gamma convergence function\n",
    "gamma ← {DONTE × 1 - *-(|⍵)÷DONTE}\n",
    "```\n",
    "\n",
    "### Key APL Advantages\n",
    "- Vectorized operations on entire arrays\n",
    "- Natural expression of mathematical formulas\n",
    "- Compact code (often 10x shorter than Python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Python simulation of APL-style array operations\n",
    "def apl_style_computation(errors, dt, lambda_val=0.16905, donte=149.9992314000):\n",
    "    \"\"\"Vectorized computation mimicking APL style\"\"\"\n",
    "    # Generate time indices\n",
    "    t = np.arange(len(errors)) * dt\n",
    "    \n",
    "    # Exponential weights (APL-style vector operation)\n",
    "    weights = np.exp(-lambda_val * t)\n",
    "    \n",
    "    # Cumulative exponentially weighted error\n",
    "    Ec = np.cumsum(errors * weights) * dt\n",
    "    \n",
    "    # Psi computation (vectorized)\n",
    "    psi = errors + lambda_val * Ec\n",
    "    \n",
    "    # Gamma convergence (vectorized)\n",
    "    gamma = donte * (1.0 - np.exp(-np.abs(psi) / donte))\n",
    "    \n",
    "    return psi, gamma, Ec\n",
    "\n",
    "# Benchmark vectorized operations\n",
    "def benchmark_vectorized(size=10000):\n",
    "    errors = np.sin(np.linspace(0, 100, size))\n",
    "    dt = 0.001\n",
    "    \n",
    "    start = perf_counter()\n",
    "    psi, gamma, Ec = apl_style_computation(errors, dt)\n",
    "    end = perf_counter()\n",
    "    \n",
    "    return (end - start) * 1000\n",
    "\n",
    "apl_time = benchmark_vectorized()\n",
    "print(f\"\\nVectorized (APL-style) execution time: {apl_time:.2f} ms for 10,000 points\")\n",
    "print(f\"Speedup vs Python loop: {python_time/apl_time:.1f}x\")\n",
    "\n",
    "# Visualize APL-style array operations\n",
    "errors = np.sin(np.linspace(0, 20, 1000))\n",
    "dt = 0.01\n",
    "psi, gamma, Ec = apl_style_computation(errors, dt)\n",
    "t = np.arange(len(errors)) * dt\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "axes[0, 0].plot(t, errors, 'b-', linewidth=1.5)\n",
    "axes[0, 0].set_title('Input Error Signal', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Error', fontsize=10)\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[0, 1].plot(t, Ec, 'g-', linewidth=1.5)\n",
    "axes[0, 1].set_title('Exponentially Weighted Memory (Ec)', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Ec', fontsize=10)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 0].plot(t, psi, 'r-', linewidth=1.5)\n",
    "axes[1, 0].set_title('Primal State (ψ)', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Time (s)', fontsize=10)\n",
    "axes[1, 0].set_ylabel('ψ', fontsize=10)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 1].plot(t, gamma, 'm-', linewidth=1.5)\n",
    "axes[1, 1].set_title('Convergence Function (γ)', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Time (s)', fontsize=10)\n",
    "axes[1, 1].set_ylabel('γ', fontsize=10)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prolog Implementation\n",
    "\n",
    "Prolog is used for:\n",
    "- Logical reasoning\n",
    "- Compliance checking (FDA, NHTSA, FAA)\n",
    "- Action planning (LAM system)\n",
    "- Rule-based decision making\n",
    "\n",
    "### Prolog Code Example\n",
    "\n",
    "```prolog\n",
    "% Primal Logic reasoning rules\n",
    "stable_convergence(Psi, Gamma) :-\n",
    "    abs(Psi) < 150.0,\n",
    "    Gamma >= 0,\n",
    "    Gamma =< 149.9992314000.\n",
    "\n",
    "% Check control safety\n",
    "safe_control(Error, Control) :-\n",
    "    abs(Error) < 10.0,\n",
    "    abs(Control) < 100.0,\n",
    "    lipschitz_bounded(Control).\n",
    "\n",
    "% Compliance checking\n",
    "fda_compliant(Device) :-\n",
    "    has_bounds(Device),\n",
    "    convergence_proven(Device),\n",
    "    safety_validated(Device).\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Python simulation of Prolog-style reasoning\n",
    "class PrologStyleReasoning:\n",
    "    \"\"\"Simulate Prolog-style logical reasoning in Python\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def stable_convergence(psi, gamma, donte=149.9992314000):\n",
    "        \"\"\"Check if convergence is stable\"\"\"\n",
    "        return abs(psi) < 150.0 and 0 <= gamma <= donte\n",
    "    \n",
    "    @staticmethod\n",
    "    def safe_control(error, control):\n",
    "        \"\"\"Check if control signal is safe\"\"\"\n",
    "        return abs(error) < 10.0 and abs(control) < 100.0\n",
    "    \n",
    "    @staticmethod\n",
    "    def fda_compliant(has_bounds, convergence_proven, safety_validated):\n",
    "        \"\"\"Check FDA compliance\"\"\"\n",
    "        return has_bounds and convergence_proven and safety_validated\n",
    "    \n",
    "    @staticmethod\n",
    "    def action_valid(action, preconditions, effects):\n",
    "        \"\"\"Check if action can be executed\"\"\"\n",
    "        return all(preconditions) and len(effects) > 0\n",
    "\n",
    "# Example: Reasoning about control states\n",
    "reasoning = PrologStyleReasoning()\n",
    "\n",
    "test_cases = [\n",
    "    {'psi': 5.0, 'gamma': 100.0, 'error': 2.0, 'control': 15.0},\n",
    "    {'psi': 200.0, 'gamma': 100.0, 'error': 2.0, 'control': 15.0},\n",
    "    {'psi': 5.0, 'gamma': 100.0, 'error': 15.0, 'control': 15.0},\n",
    "]\n",
    "\n",
    "print(\"\\nProlog-style reasoning results:\")\n",
    "print(\"=\"*60)\n",
    "for i, case in enumerate(test_cases, 1):\n",
    "    stable = reasoning.stable_convergence(case['psi'], case['gamma'])\n",
    "    safe = reasoning.safe_control(case['error'], case['control'])\n",
    "    \n",
    "    print(f\"\\nTest case {i}:\")\n",
    "    print(f\"  ψ={case['psi']:.1f}, γ={case['gamma']:.1f}\")\n",
    "    print(f\"  error={case['error']:.1f}, control={case['control']:.1f}\")\n",
    "    print(f\"  Stable convergence: {stable}\")\n",
    "    print(f\"  Safe control: {safe}\")\n",
    "    print(f\"  Overall valid: {stable and safe}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. D Language Implementation\n",
    "\n",
    "D provides:\n",
    "- High-performance compiled code\n",
    "- Real-time control (~0.1ms loop latency)\n",
    "- Memory safety with performance\n",
    "- 100x faster than Python for control loops\n",
    "\n",
    "### D Code Example\n",
    "\n",
    "```d\n",
    "// High-performance Primal Logic kernel in D\n",
    "struct PrimalKernel {\n",
    "    double lambda = 0.16905;\n",
    "    double donte = 149.9992314000;\n",
    "    double psi = 0.0;\n",
    "    double gamma = 0.0;\n",
    "    double Ec = 0.0;\n",
    "    \n",
    "    void update(double error, double dt) @nogc nothrow {\n",
    "        import std.math : exp, abs;\n",
    "        \n",
    "        // Exponential decay\n",
    "        double decay = exp(-lambda * dt);\n",
    "        Ec = Ec * decay + error * dt;\n",
    "        \n",
    "        // State updates\n",
    "        psi = error + lambda * Ec;\n",
    "        gamma = donte * (1.0 - exp(-abs(psi) / donte));\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "### D Performance Characteristics\n",
    "- **Control loop latency**: ~0.1ms (vs ~10ms Python)\n",
    "- **Memory usage**: 10x lower than Python\n",
    "- **Deterministic timing**: Real-time guarantees\n",
    "- **Zero-cost abstractions**: No runtime overhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Comparison of execution times\n",
    "languages = ['Python\\n(Loop)', 'Python\\n(Vectorized)', 'D\\n(Estimated)', 'C++\\n(Estimated)']\n",
    "times_ms = [python_time, apl_time, python_time/100, python_time/120]  # D is ~100x faster\n",
    "colors = ['#3776ab', '#4CAF50', '#E74C3C', '#9b4dca']\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Linear scale\n",
    "bars1 = ax1.bar(languages, times_ms, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "ax1.set_ylabel('Execution Time (ms)', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Performance Comparison (Linear Scale)', fontsize=14, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, time in zip(bars1, times_ms):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{time:.2f}ms',\n",
    "             ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Log scale\n",
    "bars2 = ax2.bar(languages, times_ms, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "ax2.set_ylabel('Execution Time (ms, log scale)', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Performance Comparison (Log Scale)', fontsize=14, fontweight='bold')\n",
    "ax2.set_yscale('log')\n",
    "ax2.grid(True, alpha=0.3, axis='y', which='both')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Speedup comparison\n",
    "print(\"\\nSpeedup comparison (relative to Python loop):\")\n",
    "print(\"=\"*50)\n",
    "for lang, time in zip(languages, times_ms):\n",
    "    speedup = python_time / time\n",
    "    print(f\"{lang.replace(chr(10), ' '):20s}: {speedup:6.1f}x faster\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Language Selection Guide\n",
    "\n",
    "### When to use each language:\n",
    "\n",
    "| Use Case | Language | Why |\n",
    "|----------|----------|-----|\n",
    "| Prototyping algorithms | **Python** | Fast iteration, rich libraries |\n",
    "| Data analysis | **Python** | Pandas, NumPy, Matplotlib |\n",
    "| Array operations | **APL** | Concise, vectorized |\n",
    "| Signal processing | **APL** | Natural mathematical notation |\n",
    "| Logic reasoning | **Prolog** | Declarative, rule-based |\n",
    "| Compliance checking | **Prolog** | Formal verification |\n",
    "| Real-time control | **D** | Low latency, deterministic |\n",
    "| Embedded systems | **D** | Small footprint, efficient |\n",
    "| Production deployment | **D** or **C++** | Performance, reliability |\n",
    "\n",
    "### Integration Strategy\n",
    "\n",
    "1. **Develop in Python**: Rapid prototyping and validation\n",
    "2. **Optimize with APL**: Array-heavy computations\n",
    "3. **Reason with Prolog**: Safety and compliance\n",
    "4. **Deploy in D**: Production real-time systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a decision tree for language selection\n",
    "import textwrap\n",
    "\n",
    "def wrap_text(text, width=30):\n",
    "    return '\\n'.join(textwrap.wrap(text, width=width))\n",
    "\n",
    "# Decision tree data\n",
    "decisions = [\n",
    "    {\"question\": \"Need real-time performance (<1ms)?\", \"yes\": \"D\", \"no\": \"Continue\"},\n",
    "    {\"question\": \"Logic/rule-based reasoning?\", \"yes\": \"Prolog\", \"no\": \"Continue\"},\n",
    "    {\"question\": \"Heavy array operations?\", \"yes\": \"APL\", \"no\": \"Python\"},\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LANGUAGE SELECTION DECISION TREE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i, decision in enumerate(decisions, 1):\n",
    "    print(f\"\\n{i}. {decision['question']}\")\n",
    "    print(f\"   YES → {decision['yes']}\")\n",
    "    print(f\"   NO  → {decision['no']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cross-Language Example: Same Algorithm\n",
    "\n",
    "Let's implement the same step response in multiple languages conceptually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"=\"*70)\n",
    "print(\"SAME ALGORITHM IN DIFFERENT LANGUAGES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n### PYTHON ###\")\n",
    "print(\"\"\"\n",
    "def step_response(setpoint, duration, dt):\n",
    "    controller = PrimalLogic()\n",
    "    state = 0.0\n",
    "    for t in np.arange(0, duration, dt):\n",
    "        error = setpoint - state\n",
    "        psi, gamma, Ec = controller.update(error, dt)\n",
    "        state += dt * (-state + psi)\n",
    "    return state\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n### APL ###\")\n",
    "print(\"\"\"\n",
    "⍝ APL vectorized step response\n",
    "StepResponse ← {\n",
    "    t ← 0, ⍵[2], ⍵[3] ⍝ time vector\n",
    "    errors ← ⍵[0] - state\n",
    "    psi ← errors + LAMBDA × (+\\\\errors × *-LAMBDA×t)\n",
    "    state ← state + ⍵[3] × (-state + psi)\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n### PROLOG ###\")\n",
    "print(\"\"\"\n",
    "% Prolog step response with constraints\n",
    "step_response(Setpoint, Duration, Dt, State) :-\n",
    "    initial_state(0.0, Controller),\n",
    "    simulate_steps(Setpoint, Duration, Dt, Controller, State),\n",
    "    stable_convergence(State),\n",
    "    within_bounds(State, 0.0, Setpoint).\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n### D LANGUAGE ###\")\n",
    "print(\"\"\"\n",
    "// D high-performance step response\n",
    "double stepResponse(double setpoint, double duration, double dt) @nogc {\n",
    "    auto controller = PrimalKernel();\n",
    "    double state = 0.0;\n",
    "    for (double t = 0; t < duration; t += dt) {\n",
    "        double error = setpoint - state;\n",
    "        controller.update(error, dt);\n",
    "        state += dt * (-state + controller.psi);\n",
    "    }\n",
    "    return state;\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "MotorHandPro's multi-language architecture provides:\n",
    "\n",
    "1. **Flexibility**: Choose the right tool for each task\n",
    "2. **Performance**: D/C++ for real-time, Python for analysis\n",
    "3. **Expressiveness**: APL for math, Prolog for logic\n",
    "4. **Validation**: Cross-verify implementations across languages\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Explore `apl/` directory for APL implementations\n",
    "- Check `prolog/` for logical reasoning examples\n",
    "- See `dlang/` for high-performance D code\n",
    "- Continue to notebook `03_fixed_point_convergence.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "colab": {
   "provenance": [],
   "include_colab_link": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
